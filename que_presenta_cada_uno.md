# DIVISI√ìN DE CONTENIDO - PRESENTACI√ìN GRUPAL (4 PERSONAS)

## ‚è±Ô∏è TIEMPO TOTAL: 15 MINUTOS
- **Presentaci√≥n grupal:** 12 minutos (3 min por persona)
- **Exposici√≥n del script:** 3 minutos (Persona 4)

---

## üë§ PERSONA 1: INTRODUCCI√ìN Y CONTEXTO (3 minutos)

### Slides a presentar: 1-5

**Slide 1: Portada**
- Presentar el equipo y saludar
- Mencionar el t√≠tulo del proyecto

**Slide 2-3: ¬øQu√© es el Aprendizaje Supervisado?**
- Explicar concepto de ML supervisado (datos etiquetados)
- Diferenciar clasificaci√≥n vs regresi√≥n
- Mencionar que se usar√° regresi√≥n

**Slide 4: Algoritmos Utilizados**
- Nombrar los 5 algoritmos:
  1. Regresi√≥n Lineal (baseline)
  2. √Årbol de Decisi√≥n (captura no linealidades)
  3. Red Neuronal (aproximador universal)
  4. SVM-Œµ (robusto a outliers)
  5. K-NN (basado en vecinos)
- Explicar brevemente cada uno (1 frase por algoritmo)

**Slide 5: Variables y Justificaci√≥n**
- **Variable dependiente:** Duration_hrs (continua, 118 valores √∫nicos)
- **Variables independientes:** Length_km, Commune, Latitud, Longitud, Speed_kmh, etc. (24 features finales)
- **Justificaci√≥n regresi√≥n:** 118 valores √∫nicos ‚Üí continua, no categ√≥rica. M√°s √∫til predecir "2.5 horas" que clasificar en categor√≠as

### Script sugerido:
> "Buenos d√≠as. Somos [nombres] y presentamos nuestro an√°lisis de congesti√≥n vehicular en Santiago usando Machine Learning. El aprendizaje supervisado utiliza datos etiquetados para entrenar modelos predictivos. Comparamos 5 algoritmos: regresi√≥n lineal como baseline, √°rboles de decisi√≥n para capturar no linealidades, redes neuronales, SVM y K-NN. Nuestra variable objetivo es la duraci√≥n de congesti√≥n en horas, que tiene 118 valores √∫nicos, por eso elegimos regresi√≥n en lugar de clasificaci√≥n. Las variables predictoras incluyen longitud del trayecto, comuna, coordenadas geogr√°ficas y velocidad."

**Transici√≥n:**
> "Ahora [Persona 2] mostrar√° los tiempos de entrenamiento y los resultados del modelo de regresi√≥n lineal."

---

## üë§ PERSONA 2: TIEMPOS Y REGRESI√ìN LINEAL (3 minutos)

### Dashboard - Pesta√±as: Tiempos + Regresi√≥n Lineal

**‚è±Ô∏è Pesta√±a: Tiempos de Entrenamiento (1.5 min)**
- Abrir dashboard en: https://zapallo.shinyapps.io/congestion-santiago-ml/
- Navegar a "‚è±Ô∏è Tiempos Entrenamiento"
- Mostrar KPIs:
  - Tiempo total: ~33 segundos
  - Modelo m√°s r√°pido: Decision Tree (0.30s)
  - Modelo m√°s lento: SVM-Œµ (28s)
- Mostrar tabla de tiempos
- Mencionar especificaciones: 3-fold CV, 10,000 observaciones, procesador [tu modelo]

**üìà Pesta√±a: Regresi√≥n Lineal (1.5 min)**
- Navegar a "üìà Regresi√≥n Lineal"
- Mostrar tabla de coeficientes
- Explicar interpretaci√≥n:
  - Coeficientes positivos ‚Üí aumentan duraci√≥n
  - Coeficientes negativos ‚Üí disminuyen duraci√≥n
  - Magnitud indica importancia
- Destacar top 3 coeficientes m√°s grandes (ordenados en tabla)

### Script sugerido:
> "Comenzamos midiendo los tiempos de entrenamiento. Como pueden ver en el dashboard, el entrenamiento total tom√≥ 33 segundos. El √°rbol de decisi√≥n fue el m√°s r√°pido con 0.3 segundos, mientras que SVM tom√≥ 28 segundos por su complejidad. La regresi√≥n lineal nos muestra los coeficientes de cada variable. Los valores positivos aumentan la duraci√≥n de congesti√≥n, los negativos la reducen. Pueden ver la magnitud de impacto de cada feature ordenada en esta tabla interactiva."

**Transici√≥n:**
> "Continuamos con [Persona 3] quien mostrar√° las visualizaciones de los modelos m√°s complejos."

---

## üë§ PERSONA 3: MODELOS COMPLEJOS Y COMPARACI√ìN (3 minutos)

### Dashboard - Pesta√±as: √Årbol + Red Neuronal + Comparaci√≥n

**üå≥ Pesta√±a: √Årbol de Decisi√≥n (1 min)**
- Navegar a "üå≥ √Årbol de Decisi√≥n"
- Mostrar visualizaci√≥n del √°rbol
- Explicar:
  - Cada nodo representa una decisi√≥n (ej: "Length_km < 5?")
  - Colores indican magnitud de predicci√≥n
  - Par√°metro √≥ptimo: cp (complexity parameter) elegido por CV

**üß† Pesta√±a: Red Neuronal (1 min)**
- Navegar a "üß† Red Neuronal"
- Mostrar arquitectura visual
- Explicar:
  - Capa de entrada (24 features)
  - Capa oculta (3 o 5 neuronas)
  - Capa de salida (Duration_hrs)
  - Conexiones representan pesos aprendidos

**üìä Pesta√±a: Comparaci√≥n Modelos (1 min)**
- Navegar a "üìä Comparaci√≥n Modelos"
- Mostrar gr√°fico de barras con RMSE
- Destacar:
  - **K-NN ganador:** RMSE = 0.9348 (menor es mejor)
  - Neural Network segundo: RMSE = 0.9499
  - SVM √∫ltimo: RMSE = 0.9966
- Mostrar tabla con todas las m√©tricas y hiperpar√°metros √≥ptimos

### Script sugerido:
> "El √°rbol de decisi√≥n visualizado aqu√≠ muestra c√≥mo el modelo toma decisiones mediante reglas jer√°rquicas. Cada nodo pregunta sobre una variable, como si la longitud es menor a 5 km. La red neuronal tiene 24 entradas correspondientes a nuestras features, una capa oculta con 3 o 5 neuronas, y produce la predicci√≥n final. Al comparar todos los modelos, K-NN obtuvo el mejor desempe√±o con RMSE de 0.9348 horas, equivalente a ~56 minutos de error cuadr√°tico medio. Esta tabla muestra todas las m√©tricas y los hiperpar√°metros √≥ptimos encontrados por validaci√≥n cruzada."

**Transici√≥n:**
> "Finalmente, [Persona 4] presentar√° los resultados en datos de prueba y las conclusiones del proyecto."

---

## üë§ PERSONA 4: VALIDACI√ìN TEST, CONCLUSIONES Y C√ìDIGO (6 minutos)

### Dashboard - Pesta√±as: Validaci√≥n Test + Gr√°ficos + C√≥digo (3 min presentaci√≥n + 3 min script)

**üìã Pesta√±a: Validaci√≥n Test (1.5 min)**
- Navegar a "üìã Tabla Validaci√≥n Test"
- Explicar importancia de test set (nunca visto durante entrenamiento)
- Mostrar KPIs del modelo ganador K-NN:
  - **RMSE:** 0.9348 horas (~56 min error cuadr√°tico)
  - **MAE:** 0.5109 horas (~31 min error promedio) ‚Üê **M√©trica m√°s interpretable**
  - **R¬≤:** 20.61% (varianza explicada)
  - **MAPE:** 77.35%
- Destacar que MAE de 31 minutos es √∫til para planificaci√≥n

**üìâ Pesta√±a: Residuales & Gr√°ficos (1.5 min)**
- Navegar a "üìâ Residuales & Gr√°ficos"
- Mostrar gr√°fico de residuales:
  - Explicar: puntos cercanos a l√≠nea diagonal = buenas predicciones
  - Dispersi√≥n indica error
- Mostrar importancia de variables:
  - **Top 3:** Length_km, Commune_Santiago, Longitud
  - Interpretaci√≥n de cada una

**Conclusiones (Solo verbal - regresar a slide 14 en PowerPoint si lo tienen)**
- Modelo ganador: K-NN con error promedio de 31 minutos
- Variables clave: longitud del trayecto y ubicaci√≥n geogr√°fica
- Limitaciones: R¬≤ bajo (20.6%) debido a aleatoriedad del tr√°fico (clima, accidentes)
- Aplicaciones: planificaci√≥n urbana, informaci√≥n ciudadana
- Mejoras futuras: m√°s variables (clima, eventos), dataset completo (76k obs)

---

### üñ•Ô∏è EXPOSICI√ìN DEL SCRIPT (3 minutos)

**Abrir VSCode o RStudio y mostrar:**

1. **Archivo: `analisis_completo.R` (1 min)**
   - Mostrar estructura general (scroll r√°pido)
   - Destacar secciones clave:
     * Carga de librer√≠as (l√≠neas 1-23)
     * Preprocesamiento (detecci√≥n de outliers, one-hot encoding)
     * Medici√≥n de tiempos de entrenamiento (mostrar c√≥digo de `Sys.time()`)
     * Entrenamiento de 5 modelos con `caret::train()`
     * Generaci√≥n de visualizaciones (√°rbol con `rpart.plot`, red neuronal con `plotnet`)

2. **Archivo: `knn_modelo.R` (1 min)**
   - Explicar que es el modelo ganador standalone
   - Mostrar secci√≥n de entrenamiento K-NN
   - Mostrar que genera `knn_modelo.rds` para reutilizaci√≥n

3. **Archivo: `app.R` (1 min)**
   - Explicar brevemente estructura Shiny (ui + server)
   - Mostrar c√≥mo carga los datos (l√≠neas de `read.csv`, `readRDS`)
   - Mostrar ejemplo de una pesta√±a (ej: c√≥digo de gr√°fico de tiempos con Plotly)
   - Mencionar que est√° desplegado en ShinyApps.io

**Cierre:**
> "Todos los archivos est√°n documentados y reproducibles con `set.seed(123)`. El proyecto est√° disponible en nuestro repositorio GitHub y el dashboard en https://zapallo.shinyapps.io/congestion-santiago-ml/. ¬øPreguntas?"

---

## üìä RESUMEN DE DISTRIBUCI√ìN

| Persona | Contenido | Tiempo | Herramientas |
|---------|-----------|--------|--------------|
| **1** | Introducci√≥n, algoritmos, variables | 3 min | PowerPoint/Canva (Slides 1-5) |
| **2** | Tiempos + Regresi√≥n Lineal | 3 min | Dashboard (2 pesta√±as) |
| **3** | √Årbol + Red + Comparaci√≥n | 3 min | Dashboard (3 pesta√±as) |
| **4** | Validaci√≥n + Conclusiones + C√≥digo | 3 min + 3 min | Dashboard (2 pesta√±as) + VSCode |

---

## üéØ TIPS PARA COORDINACI√ìN

### Transiciones suaves:
- Persona 1 ‚Üí 2: "Ahora veremos los resultados t√©cnicos en el dashboard..."
- Persona 2 ‚Üí 3: "Continuamos con modelos m√°s complejos..."
- Persona 3 ‚Üí 4: "Finalmente, validaci√≥n y conclusiones..."

### Durante Q&A:
- Persona 1: preguntas te√≥ricas (algoritmos, metodolog√≠a)
- Persona 2: preguntas sobre tiempos, eficiencia
- Persona 3: preguntas sobre modelos complejos
- Persona 4: preguntas sobre resultados, c√≥digo, conclusiones

---

## ‚úÖ CHECKLIST PRE-PRESENTACI√ìN

**Persona 1:**
- [ ] Slides 1-5 en PowerPoint/Canva listos
- [ ] Memorizar concepto de aprendizaje supervisado
- [ ] Practicar explicaci√≥n de 5 algoritmos (1 frase cada uno)

**Persona 2:**
- [ ] Dashboard abierto en navegador
- [ ] Practicar navegaci√≥n pesta√±a "Tiempos" y "Regresi√≥n Lineal"
- [ ] Memorizar datos del procesador

**Persona 3:**
- [ ] Practicar explicaci√≥n visual de √°rbol y red neuronal
- [ ] Saber destacar modelo ganador en gr√°fico comparativo
- [ ] Memorizar RMSE del ganador (0.9348)

**Persona 4:**
- [ ] Tener VSCode/RStudio abierto con archivos listos
- [ ] Practicar scroll r√°pido en `analisis_completo.R`
- [ ] Memorizar conclusiones clave (MAE 31 min, R¬≤ 20.6%)
- [ ] Tener URL del dashboard lista para mencionar

---

